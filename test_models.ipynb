{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adithya Palle \\\n",
    "March 30, 2025 \\\n",
    "Final Project\n",
    "\n",
    "Jupyter Notebook for running CNN and optical flow models on the stream of data and determining classfication accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_extraction import get_video_data, FIRE_VIDEOS_DATA_PATH\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_fire_videos, val_no_fire_videos = get_video_data(os.path.join(FIRE_VIDEOS_DATA_PATH, \"validation\"))\n",
    "test_fire_videos, test_no_fire_videos = get_video_data(os.path.join(FIRE_VIDEOS_DATA_PATH, \"test\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from video_model import VideoModel, VideoModelFromImageModel\n",
    "from cnn import CNNFireDetector\n",
    "from train_cnn import InferenceModel, TrainingModel, TRANSFORM\n",
    "from optical_flow import FarnebackOpticalFlowModel\n",
    "import torch\n",
    "# Load models\n",
    "\n",
    "\n",
    "# TODO: initialize your models here\n",
    "\n",
    "MODEL_NAME = \"final_exp\"\n",
    "device = torch.device(\"cpu\")#torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "my_image_model : VideoModel = VideoModelFromImageModel(CNNFireDetector.load_from_file(f\"data/{MODEL_NAME}.pth\", InferenceModel(TrainingModel()), device =device, transform = TRANSFORM ))\n",
    "optical_flow_model : VideoModel = FarnebackOpticalFlowModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 17:20:21.327 python[10403:192121] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-04-02 17:20:21.327 python[10403:192121] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m CHOSEN_MODEL \u001b[38;5;241m=\u001b[39m optical_flow_model\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# TODO: run all the below code for each model separately and compare results (make function)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m val_fire_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mget_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCHOSEN_MODEL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_fire_videos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m val_no_fire_predictions \u001b[38;5;241m=\u001b[39m get_predictions(CHOSEN_MODEL, val_no_fire_videos)\n",
      "File \u001b[0;32m~/work/CS5330/fire_detection/prediction.py:23\u001b[0m, in \u001b[0;36mget_predictions\u001b[0;34m(model, videos)\u001b[0m\n\u001b[1;32m     21\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m video \u001b[38;5;129;01min\u001b[39;00m videos:\n\u001b[0;32m---> 23\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_on_full_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "File \u001b[0;32m~/work/CS5330/fire_detection/video_model.py:46\u001b[0m, in \u001b[0;36mVideoModel.predict_on_full_video\u001b[0;34m(self, video)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m video:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# build up the stream of frames\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     frames\u001b[38;5;241m.\u001b[39mappend(frame)\n\u001b[0;32m---> 46\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_on_last_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(prediction)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "File \u001b[0;32m~/work/CS5330/fire_detection/optical_flow.py:93\u001b[0m, in \u001b[0;36mFarnebackOpticalFlowModel.predict_on_last_frame\u001b[0;34m(self, frames)\u001b[0m\n\u001b[1;32m     91\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal Frame\u001b[39m\u001b[38;5;124m\"\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mcvtColor(target_frame_np, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB))\n\u001b[1;32m     92\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFire Mask\u001b[39m\u001b[38;5;124m\"\u001b[39m, fire_mask)\n\u001b[0;32m---> 93\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fire_prob\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from prediction import get_predictions_on_videos, get_false_positive_rate, get_recall, get_accuracy\n",
    "CHOSEN_MODEL = my_image_model\n",
    "# TODO: run all the below code for each model separately and compare results (make function)\n",
    "val_fire_predictions, _ , _ = get_predictions_on_videos(CHOSEN_MODEL, val_fire_videos)\n",
    "val_no_fire_predictions, _ , _ = get_predictions_on_videos(CHOSEN_MODEL, val_no_fire_videos)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use recall and FPR curve to determine best threshold for binarizing predictions\n",
    "recalls = []\n",
    "fprs = []\n",
    "thresholds = [n/100 for n in range(5, 100, 5)] # threshold above which a prediction probabiltiy is considered fire\n",
    "for threshold in thresholds:\n",
    "    recall = get_recall(val_fire_predictions, threshold)\n",
    "    false_positive_rate = get_false_positive_rate(val_no_fire_predictions, threshold)\n",
    "    recalls.append(recall)\n",
    "    fprs.append(false_positive_rate)\n",
    "\n",
    "\n",
    "# plot recall vs false positive rate\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fprs, recalls)\n",
    "\n",
    "# add point lables with threshold\n",
    "for i in range(0, len(thresholds) , 2):\n",
    "    txt = thresholds[i]\n",
    "    plt.annotate(txt, (fprs[i], recalls[i]), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('Recall')\n",
    "plt.title('Recall vs False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_THRESHOLD = 0.9 # TODO:  manually choose the best threshold based on the plot\n",
    "\n",
    "\n",
    "# get results on test videos\n",
    "test_fire_predictions, total_time_ms_fire, total_fire_frames = get_predictions_on_videos(CHOSEN_MODEL, test_fire_videos)\n",
    "test_no_fire_predictions, total_time_ms_nofire, total_nofire_frames = get_predictions_on_videos(CHOSEN_MODEL, test_no_fire_videos)\n",
    "test_recall = get_recall(test_fire_predictions, BEST_THRESHOLD)\n",
    "test_fpr = get_false_positive_rate(test_no_fire_predictions, BEST_THRESHOLD)\n",
    "test_accuracy = get_accuracy(test_fire_predictions, test_no_fire_predictions, BEST_THRESHOLD) # TODO: fix\n",
    "print(\"Test Accuracy: \", test_accuracy)\n",
    "print(\"Test Recall: \", test_recall)\n",
    "print(\"Test False Positive Rate: \", test_fpr)\n",
    "\n",
    "total_time_ms = total_time_ms_fire + total_time_ms_nofire\n",
    "total_frames = total_fire_frames + total_nofire_frames\n",
    "avg_time_per_frame = total_time_ms / total_frames\n",
    "print(\"Average time per frame (ms): \", avg_time_per_frame, \" on device: \" , device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_fire_videos\n",
    "del test_no_fire_videos\n",
    "del val_fire_videos\n",
    "del val_no_fire_videos\n",
    "# gpu cleanup\n",
    "\n",
    "if torch.cuda.is_available(): \n",
    "    torch.cuda.empty_cache()  # Frees GPU memory from deleted tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from data_extraction import load_frames_from_video\n",
    "\n",
    "def save_video(frames, predictions, filename, threshold=0.5, fps=30):\n",
    "    _ , h, w = np.array(frames[0]).shape\n",
    "    out_path = os.path.join(\"data\", filename)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"avc1\")  # use 'avc1' or 'XVID' if mp4v fails\n",
    "    writer = cv2.VideoWriter()\n",
    "    succes  = writer.open(out_path, fourcc, fps, (w, h))\n",
    "    if not succes:\n",
    "        raise Exception(f\"Could not open video writer for {out_path}\")\n",
    "    for i, frame in enumerate(frames):\n",
    "        # frame is in (C,H,W) format\n",
    "        frame = frame.permute(1, 2, 0).numpy()  # convert (C, H, W) -> (H, W, C)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def predict_on_video(model: VideoModel, video_path : str, save_name : str):\n",
    "    if not os.path.isfile(video_path):\n",
    "        raise ValueError(\"Invalid video_path\")\n",
    "    frames = load_frames_from_video(video_path)\n",
    "    predictions = model.predict_on_full_video(frames)\n",
    "    save_video(frames, predictions, save_name)\n",
    "    \n",
    "\n",
    "def save_video(frames, predictions, filename, threshold=BEST_THRESHOLD, fps=30):\n",
    "    _ , h, w = np.array(frames[0]).shape\n",
    "    out_path = os.path.join(\"data\", filename)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # use 'avc1' or 'XVID' if mp4v fails\n",
    "    writer = cv2.VideoWriter()\n",
    "    succes  = writer.open(out_path, fourcc, fps, (w, h))\n",
    "    if not succes:\n",
    "        raise Exception(f\"Could not open video writer for {out_path}\")\n",
    "    for i, frame in enumerate(frames):\n",
    "        # frame is in (C,H,W) format\n",
    "        frame = frame.permute(1, 2, 0).numpy()  # convert (C, H, W) -> (H, W, C)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        text = \"Fire\" if predictions[i] >= threshold else \"No Fire\"\n",
    "        color = (0, 0, 255) if text == \"Fire\" else (0, 255, 0)\n",
    "        cv2.putText(frame, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "        writer.write(frame)\n",
    "\n",
    "    writer.release()\n",
    "    print(f\"Saved: {out_path}\")\n",
    "\n",
    "# Predict on the fire starting video and save result\n",
    "predict_on_video(CHOSEN_MODEL, \"data/efan_fire.mp4\", \"efan_pred.mp4\")\n",
    "\n",
    "#predict on video of fire and save \n",
    "predict_on_video(CHOSEN_MODEL, \"data/fire_videos/test/pos/posVideo1.868.avi\", \"fire_vid_pred.mp4\")\n",
    "# predict on video of no fire and save\n",
    "predict_on_video(CHOSEN_MODEL, \"data/fire_videos/test/neg/negsVideo1.858.avi\", \"nofire_vid_pred.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu cleanup\n",
    "\n",
    "if torch.cuda.is_available(): \n",
    "    torch.cuda.empty_cache()  # Frees GPU memory from deleted tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
