{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adithya Palle \\\n",
    "March 30, 2025 \\\n",
    "Final Project\n",
    "\n",
    "Jupyter Notebook for running CNN and optical flow models on the stream of data and determining classfication accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_extraction import get_video_data, FIRE_VIDEOS_DATA_PATH\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_fire_videos, val_no_fire_videos = get_video_data(os.path.join(FIRE_VIDEOS_DATA_PATH, \"validation\"))\n",
    "test_fire_videos, test_no_fire_videos = get_video_data(os.path.join(FIRE_VIDEOS_DATA_PATH, \"test\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from video_model import VideoModel, VideoModelFromImageModel\n",
    "from cnn import CNNFireDetector\n",
    "from train_cnn import InferenceModel, TrainingModel, TRANSFORM\n",
    "from optical_flow import FarnebackOpticalFlowModel\n",
    "import torch\n",
    "# Load models\n",
    "\n",
    "\n",
    "# TODO: initialize your models here\n",
    "\n",
    "MODEL_NAME = \"final_exp\"\n",
    "device = torch.device(\"cpu\")#torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "my_image_model : VideoModel = VideoModelFromImageModel(CNNFireDetector.load_from_file(f\"data/{MODEL_NAME}.pth\", InferenceModel(TrainingModel()), device =device, transform = TRANSFORM ))\n",
    "optical_flow_model : VideoModel = FarnebackOpticalFlowModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prediction import get_predictions_on_videos, get_false_positive_rate, get_recall, get_accuracy\n",
    "CHOSEN_MODEL = my_image_model\n",
    "# TODO: run all the below code for each model separately and compare results (make function)\n",
    "val_fire_predictions, _ , _ = get_predictions_on_videos(CHOSEN_MODEL, val_fire_videos)\n",
    "val_no_fire_predictions, _ , _ = get_predictions_on_videos(CHOSEN_MODEL, val_no_fire_videos)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use recall and FPR curve to determine best threshold for binarizing predictions\n",
    "recalls = []\n",
    "fprs = []\n",
    "thresholds = [n/100 for n in range(5, 100, 5)] # threshold above which a prediction probabiltiy is considered fire\n",
    "for threshold in thresholds:\n",
    "    recall = get_recall(val_fire_predictions, threshold)\n",
    "    false_positive_rate = get_false_positive_rate(val_no_fire_predictions, threshold)\n",
    "    recalls.append(recall)\n",
    "    fprs.append(false_positive_rate)\n",
    "\n",
    "\n",
    "# plot recall vs false positive rate\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fprs, recalls)\n",
    "\n",
    "# add point lables with threshold\n",
    "for i in range(0, len(thresholds) , 2):\n",
    "    txt = thresholds[i]\n",
    "    plt.annotate(txt, (fprs[i], recalls[i]), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('Recall')\n",
    "plt.title('Recall vs False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_THRESHOLD = 0.9 # TODO:  manually choose the best threshold based on the plot\n",
    "\n",
    "\n",
    "# get results on test videos\n",
    "test_fire_predictions, total_time_ms_fire, total_fire_frames = get_predictions_on_videos(CHOSEN_MODEL, test_fire_videos)\n",
    "test_no_fire_predictions, total_time_ms_nofire, total_nofire_frames = get_predictions_on_videos(CHOSEN_MODEL, test_no_fire_videos)\n",
    "test_recall = get_recall(test_fire_predictions, BEST_THRESHOLD)\n",
    "test_fpr = get_false_positive_rate(test_no_fire_predictions, BEST_THRESHOLD)\n",
    "test_accuracy = get_accuracy(test_fire_predictions, test_no_fire_predictions, BEST_THRESHOLD) # TODO: fix\n",
    "print(\"Test Accuracy: \", test_accuracy)\n",
    "print(\"Test Recall: \", test_recall)\n",
    "print(\"Test False Positive Rate: \", test_fpr)\n",
    "\n",
    "total_time_ms = total_time_ms_fire + total_time_ms_nofire\n",
    "total_frames = total_fire_frames + total_nofire_frames\n",
    "avg_time_per_frame = total_time_ms / total_frames\n",
    "print(\"Average time per frame (ms): \", avg_time_per_frame, \" on device: \" , device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_fire_videos\n",
    "del test_no_fire_videos\n",
    "del val_fire_videos\n",
    "del val_no_fire_videos\n",
    "# gpu cleanup\n",
    "\n",
    "if torch.cuda.is_available(): \n",
    "    torch.cuda.empty_cache()  # Frees GPU memory from deleted tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from data_extraction import load_frames_from_video\n",
    "\n",
    "\n",
    "def predict_on_video(model: VideoModel, video_path : str, save_name : str):\n",
    "    if not os.path.isfile(video_path):\n",
    "        raise ValueError(\"Invalid video_path\")\n",
    "    frames = load_frames_from_video(video_path)\n",
    "    predictions = model.predict_on_full_video(frames)\n",
    "    save_video(frames, predictions, save_name)\n",
    "    \n",
    "\n",
    "def save_video(frames, predictions, filename, threshold=BEST_THRESHOLD, fps=30):\n",
    "    _ , h, w = np.array(frames[0]).shape\n",
    "    out_path = os.path.join(\"data\", filename)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # use 'avc1' or 'XVID' if mp4v fails\n",
    "    writer = cv2.VideoWriter()\n",
    "    succes  = writer.open(out_path, fourcc, fps, (w, h))\n",
    "    if not succes:\n",
    "        raise Exception(f\"Could not open video writer for {out_path}\")\n",
    "    for i, frame in enumerate(frames):\n",
    "        # frame is in (C,H,W) format\n",
    "        frame = frame.permute(1, 2, 0).numpy()  # convert (C, H, W) -> (H, W, C)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        text = \"Fire\" if predictions[i] >= threshold else \"No Fire\"\n",
    "        color = (0, 0, 255) if text == \"Fire\" else (0, 255, 0)\n",
    "        cv2.putText(frame, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "        writer.write(frame)\n",
    "\n",
    "    writer.release()\n",
    "    print(f\"Saved: {out_path}\")\n",
    "\n",
    "# Predict on the fire starting video and save result\n",
    "predict_on_video(CHOSEN_MODEL, \"data/efan_fire.mp4\", \"efan_pred.mp4\")\n",
    "\n",
    "#predict on video of fire and save \n",
    "predict_on_video(CHOSEN_MODEL, \"data/fire_videos/test/pos/posVideo1.868.avi\", \"fire_vid_pred.mp4\")\n",
    "# predict on video of no fire and save\n",
    "predict_on_video(CHOSEN_MODEL, \"data/fire_videos/test/neg/negsVideo1.858.avi\", \"nofire_vid_pred.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu cleanup\n",
    "\n",
    "if torch.cuda.is_available(): \n",
    "    torch.cuda.empty_cache()  # Frees GPU memory from deleted tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
