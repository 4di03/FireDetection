{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adithya Palle \\\n",
    "March 30, 2025 \\\n",
    "Final Project\n",
    "\n",
    "Jupyter Notebook for running CNN and optical flow models on the stream of data and determining classfication accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_extraction import get_video_data, FIRE_VIDEOS_DATA_PATH\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_fire_videos, val_no_fire_videos = get_video_data(os.path.join(FIRE_VIDEOS_DATA_PATH, \"validation\"))\n",
    "test_fire_videos, test_no_fire_videos = get_video_data(os.path.join(FIRE_VIDEOS_DATA_PATH, \"test\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from video_model import VideoModel, VideoModelFromImageModel\n",
    "from cnn import CNNFireDetector\n",
    "from train_cnn import InferenceModel, TrainingModel, TRANSFORM\n",
    "from optical_flow import FarnebackOpticalFlowModel\n",
    "# Load models\n",
    "\n",
    "\n",
    "# TODO: initialize your models here\n",
    "\n",
    "\n",
    "class DummyModel(VideoModel):\n",
    "\n",
    "    def predict_on_last_frame(self, frames):\n",
    "        # random prob between 0 and 1\n",
    "        return random.uniform(0, 1)\n",
    "\n",
    "\n",
    "\n",
    "#my_image_model : VideoModel = VideoModelFromImageModel(CNNFireDetector.load_from_file(InferenceModel(TrainingModel()), \"test_model.pth\"))\n",
    "# TODO: remove and address this if you don't have time for it\n",
    "# google_net : VideoModel = DummyModel()\n",
    "# alex_net : VideoModel = DummyModel()\n",
    "optical_flow_model : VideoModel = FarnebackOpticalFlowModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nI want each model to give me a list of predictiosn for each frame in the video , so the outputs should be a list of floats in the range [0,1] for each video..\\n\\nOn Validation videos:\\n    I want to then use this list of booleans to determine Recall (TP / (TP + FN)) over all videos (only have positives in fire videos). \\n    and False Alarm Rate (FP / (FP + TN)) over all videos (only have negatives in no fire videos).\\n\\n    I will then plot a recall vs false alarm rate graph for each model to determine the best threshold.\\n\\n\\nThen, on testing videos, i will rerun this analysis with the chosen threshold and get the actual Recall and False Alarm Rate for each model.\\n\\nI will then print thiese out for emach model, and for each model show a video stream of each viedo with a \"Fire\" or \"No Fire\" \\ntext at teh top left of each frame\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "I want each model to give me a list of predictiosn for each frame in the video , so the outputs should be a list of floats in the range [0,1] for each video..\n",
    "\n",
    "On Validation videos:\n",
    "    I want to then use this list of booleans to determine Recall (TP / (TP + FN)) over all videos (only have positives in fire videos). \n",
    "    and False Alarm Rate (FP / (FP + TN)) over all videos (only have negatives in no fire videos).\n",
    "\n",
    "    I will then plot a recall vs false alarm rate graph for each model to determine the best threshold.\n",
    "\n",
    "\n",
    "Then, on testing videos, i will rerun this analysis with the chosen threshold and get the actual Recall and False Alarm Rate for each model.\n",
    "\n",
    "I will then print thiese out for emach model, and for each model show a video stream of each viedo with a \"Fire\" or \"No Fire\" \n",
    "text at teh top left of each frame\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 17:20:21.327 python[10403:192121] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-04-02 17:20:21.327 python[10403:192121] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m CHOSEN_MODEL \u001b[38;5;241m=\u001b[39m optical_flow_model\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# TODO: run all the below code for each model separately and compare results (make function)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m val_fire_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mget_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCHOSEN_MODEL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_fire_videos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m val_no_fire_predictions \u001b[38;5;241m=\u001b[39m get_predictions(CHOSEN_MODEL, val_no_fire_videos)\n",
      "File \u001b[0;32m~/work/CS5330/fire_detection/prediction.py:23\u001b[0m, in \u001b[0;36mget_predictions\u001b[0;34m(model, videos)\u001b[0m\n\u001b[1;32m     21\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m video \u001b[38;5;129;01min\u001b[39;00m videos:\n\u001b[0;32m---> 23\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_on_full_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "File \u001b[0;32m~/work/CS5330/fire_detection/video_model.py:46\u001b[0m, in \u001b[0;36mVideoModel.predict_on_full_video\u001b[0;34m(self, video)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m video:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# build up the stream of frames\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     frames\u001b[38;5;241m.\u001b[39mappend(frame)\n\u001b[0;32m---> 46\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_on_last_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(prediction)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "File \u001b[0;32m~/work/CS5330/fire_detection/optical_flow.py:93\u001b[0m, in \u001b[0;36mFarnebackOpticalFlowModel.predict_on_last_frame\u001b[0;34m(self, frames)\u001b[0m\n\u001b[1;32m     91\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal Frame\u001b[39m\u001b[38;5;124m\"\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mcvtColor(target_frame_np, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB))\n\u001b[1;32m     92\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFire Mask\u001b[39m\u001b[38;5;124m\"\u001b[39m, fire_mask)\n\u001b[0;32m---> 93\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fire_prob\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from prediction import get_predictions, get_false_positive_rate, get_recall\n",
    "CHOSEN_MODEL = optical_flow_model\n",
    "# TODO: run all the below code for each model separately and compare results (make function)\n",
    "val_fire_predictions = get_predictions(CHOSEN_MODEL, val_fire_videos)\n",
    "val_no_fire_predictions = get_predictions(CHOSEN_MODEL, val_no_fire_videos)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_recall' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m thresholds \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.4\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.6\u001b[39m, \u001b[38;5;241m0.7\u001b[39m, \u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m0.9\u001b[39m] \u001b[38;5;66;03m# threshold above which a prediction probabiltiy is considered fire\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m threshold \u001b[38;5;129;01min\u001b[39;00m thresholds:\n\u001b[0;32m----> 6\u001b[0m     recall \u001b[38;5;241m=\u001b[39m \u001b[43mget_recall\u001b[49m(val_fire_predictions, threshold)\n\u001b[1;32m      7\u001b[0m     false_positive_rate \u001b[38;5;241m=\u001b[39m get_false_positive_rate(val_no_fire_predictions, threshold)\n\u001b[1;32m      8\u001b[0m     recalls\u001b[38;5;241m.\u001b[39mappend(recall)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_recall' is not defined"
     ]
    }
   ],
   "source": [
    "# use recall and FPR curve to determine best threshold for binarizing predictions\n",
    "recalls = []\n",
    "fprs = []\n",
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9] # threshold above which a prediction probabiltiy is considered fire\n",
    "for threshold in thresholds:\n",
    "    recall = get_recall(val_fire_predictions, threshold)\n",
    "    false_positive_rate = get_false_positive_rate(val_no_fire_predictions, threshold)\n",
    "    recalls.append(recall)\n",
    "    fprs.append(false_positive_rate)\n",
    "\n",
    "\n",
    "# plot recall vs false positive rate\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fprs, recalls)\n",
    "\n",
    "# add point lables with threshold\n",
    "for i, txt in enumerate(thresholds):\n",
    "    plt.annotate(txt, (fprs[i], recalls[i]), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('Recall')\n",
    "plt.title('Recall vs False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall:  0.0\n",
      "Test False Positive Rate:  0.0\n"
     ]
    }
   ],
   "source": [
    "best_threshold = 0.5 # TODO:  manually choose the best threshold based on the plot\n",
    "\n",
    "\n",
    "# get results on test videos\n",
    "test_fire_predictions = get_predictions(CHOSEN_MODEL, test_fire_videos)\n",
    "test_no_fire_predictions = get_predictions(CHOSEN_MODEL, test_no_fire_videos)\n",
    "test_recall = get_recall(test_fire_predictions, best_threshold)\n",
    "test_fpr = get_false_positive_rate(test_no_fire_predictions, best_threshold)\n",
    "print(\"Test Recall: \", test_recall)\n",
    "print(\"Test False Positive Rate: \", test_fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1b/hwf75tz14fsffs3nqgyylfy80000gn/T/ipykernel_7594/4100558481.py:9: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  _ , h, w = np.array(frames[0]).shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: data/fire_video.mp4\n",
      "Saved: data/no_fire_video.mp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "def save_video(frames, predictions, filename, threshold=0.5, fps=30):\n",
    "    _ , h, w = np.array(frames[0]).shape\n",
    "    out_path = os.path.join(\"data\", filename)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"avc1\")  # use 'avc1' or 'XVID' if mp4v fails\n",
    "    writer = cv2.VideoWriter()\n",
    "    succes  = writer.open(out_path, fourcc, fps, (w, h))\n",
    "    if not succes:\n",
    "        raise Exception(f\"Could not open video writer for {out_path}\")\n",
    "    for i, frame in enumerate(frames):\n",
    "        # frame is in (C,H,W) format\n",
    "        frame = frame.permute(1, 2, 0).numpy()  # convert (C, H, W) -> (H, W, C)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        text = \"Fire\" if predictions[i] >= threshold else \"No Fire\"\n",
    "        color = (0, 0, 255) if text == \"Fire\" else (0, 255, 0)\n",
    "        cv2.putText(frame, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "        # print the percentages\n",
    "        cv2.putText(frame, str(predictions[i]), (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        writer.write(frame)\n",
    "\n",
    "    writer.release()\n",
    "    print(f\"Saved: {out_path}\")\n",
    "\n",
    "# Save the first fire and no-fire videos\n",
    "save_video(test_fire_videos[0], test_fire_predictions[0], \"fire_video.mp4\")\n",
    "save_video(test_no_fire_videos[0], test_no_fire_predictions[0], \"no_fire_video.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
